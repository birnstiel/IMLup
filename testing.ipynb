{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting IM Lup\n",
    "\n",
    "This code runs the MCMC simulation to calculate the best fit parameters for the disk. It uses the logprob function from logprob_parallel.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import getpass\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import astropy.units as u\n",
    "import astropy.constants as c\n",
    "from astropy.io import fits\n",
    "import emcee\n",
    "\n",
    "import dsharp_helper as dh\n",
    "import dsharp_opac as do\n",
    "import disklab\n",
    "from gofish import imagecube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import get_profile_from_fits\n",
    "from helper_functions import make_opacs\n",
    "from helper_functions import chop_forward_scattering\n",
    "from helper_functions import make_disklab2d_model\n",
    "from helper_functions import write_radmc3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from radmc3dPy import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "au = c.au.cgs.value\n",
    "M_sun = c.M_sun.cgs.value\n",
    "L_sun = c.L_sun.cgs.value\n",
    "R_sun = c.R_sun.cgs.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if getpass.getuser() == 'birnstiel':\n",
    "    radmc3d_exec = Path('~/.bin/radmc3d').expanduser()\n",
    "else:\n",
    "    radmc3d_exec = Path('~/bin/radmc3d').expanduser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALMA data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set the disk name and get some disk properties from DSHARP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disk = 'IMLup'\n",
    "fname_mm_obs = dh.get_datafile(disk)\n",
    "\n",
    "PA = dh.sources.loc[disk]['PA']\n",
    "inc = dh.sources.loc[disk]['inc']\n",
    "distance = dh.sources.loc[disk]['distance [pc]']\n",
    "\n",
    "clip = 5\n",
    "\n",
    "lam_mm = 0.125\n",
    "RMS_jyb = 14e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the radial profile from the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mm_obs, y_mm_obs, dy_mm_obs = get_profile_from_fits(\n",
    "    fname_mm_obs,\n",
    "    clip=clip,\n",
    "    inc=inc, PA=PA,\n",
    "    z0=0.0,\n",
    "    psi=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare against the DSHARP profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_prof = dh.get_profile(disk)\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.semilogy(x_mm_obs, y_mm_obs)\n",
    "ax.fill_between(x_mm_obs, y_mm_obs - dy_mm_obs, y_mm_obs + dy_mm_obs, alpha=0.5)\n",
    "\n",
    "ax.semilogy(ds_prof['r_as'], ds_prof['I_nu'])\n",
    "ax.fill_between(ds_prof['r_as'], ds_prof['I_nu_l'], ds_prof['I_nu_u'], alpha=0.5)\n",
    "\n",
    "ax.set_ylim(2e-17, 1e-13);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPHERE data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deproject the scattered light image, we will need to know where the scattering surface is. This is based on the Avenhaus et al. 2018 paper. In `imagecube` this surface can be defined with `z0` and `psi` such that its height $z$ is at\n",
    "\n",
    "$\\mathsf{z = z0 \\, \\left(\\frac{r}{arcsec}\\right)^{psi}}\\, arcsec$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0 = 0.2\n",
    "psi = 1.27\n",
    "lam_sca = 1.65e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image does not contain all the required info, so we make a copy of the fits file and modify that one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_sca_obs_orig = 'Qphi_IMLup.fits'\n",
    "fname_sca_obs = fname_sca_obs_orig.replace('.fits', '_mod.fits')\n",
    "shutil.copy(fname_sca_obs_orig, fname_sca_obs)\n",
    "\n",
    "fits.setval(fname_sca_obs, 'cdelt1', value=-3.405e-06)\n",
    "fits.setval(fname_sca_obs, 'cdelt2', value=3.405e-06)\n",
    "fits.setval(fname_sca_obs, 'crpix1', value=350.5)\n",
    "fits.setval(fname_sca_obs, 'crpix2', value=350.5)\n",
    "fits.setval(fname_sca_obs, 'crval1', value=0.0)\n",
    "fits.setval(fname_sca_obs, 'crval2', value=0.0)\n",
    "fits.setval(fname_sca_obs, 'crval3', value=1.65e-4)\n",
    "fits.setval(fname_sca_obs, 'BUNIT', value='JY/PIXEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read it with imagecube and derive a radial profile\n",
    "\n",
    "x_sca_obs, y_sca_obs, dy_sca_obs = get_profile_from_fits(\n",
    "    fname_sca_obs,\n",
    "    clip=clip,\n",
    "    inc=inc, PA=PA,\n",
    "    z0=z0,\n",
    "    psi=psi,\n",
    "    show_plots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opacities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the wavelength, size, and angle grids then calculate opacities and store them in a local file, if it doesn't exist yet.  \n",
    "**Careful, that takes of the order of >2h**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_lam = 200 # number of wavelength points\n",
    "n_a = 15 # number of particle sizes\n",
    "n_theta = 181 # number of angles in the scattering phase function\n",
    "porosity = 0.3\n",
    "\n",
    "# wavelength and particle sizes grids\n",
    "\n",
    "lam_opac = np.logspace(-5, 1, n_lam)\n",
    "a_opac = np.logspace(-5, 1, n_a)\n",
    "\n",
    "# make opacities if necessary\n",
    "\n",
    "opac_dict = make_opacs(a_opac, lam_opac, porosity=porosity, n_theta=n_theta)\n",
    "fname_opac = opac_dict['filename']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part chops the very-forward scattering part of the phase function. This part is basically the same as no scattering, but are treated by the code as a scattering event. By cutting this part out of the phase function, we avoid those non-scattering scattering events. This needs to recalculate $\\kappa_{sca}$ and $g$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_opac_chopped = fname_opac.replace('.', '_chopped.')\n",
    "\n",
    "k_sca_nochop = opac_dict['k_sca']\n",
    "g_nochop = opac_dict['g']\n",
    "\n",
    "zscat, zscat_nochop, k_sca, g = chop_forward_scattering(opac_dict)\n",
    "\n",
    "opac_dict['k_sca'] = k_sca\n",
    "opac_dict['zscat'] = zscat\n",
    "opac_dict['g'] = g\n",
    "\n",
    "rho_s = opac_dict['rho_s']\n",
    "m = 4 * np.pi / 3 * rho_s * a_opac**3\n",
    "\n",
    "do.write_disklab_opacity(fname_opac_chopped, opac_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emcee part\n",
    "\n",
    "here we define some inputs and initial parameter sets for the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining number of walkers\n",
    "nwalkers = 25\n",
    "ndim     = 7\n",
    "\n",
    "# setting the priors for some parameters instead of letting them be uniform randoms between (0.1)\n",
    "\n",
    "sigma_coeff_0   = 10**((np.random.rand(nwalkers)-0.5)*4)\n",
    "others_0        = np.random.rand(ndim-3,nwalkers)\n",
    "d2g_coeff_0     = (np.random.rand(nwalkers)+0.5) / 100\n",
    "d2g_exp_0       = (np.random.rand(nwalkers)-0.5) \n",
    "\n",
    "# the input matrix of priors\n",
    "p0 = np.vstack((sigma_coeff_0,others_0, d2g_coeff_0, d2g_exp_0)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logprob testing\n",
    "\n",
    "here we test the different steps that need to be taken in the logprob function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = p0[0, :]\n",
    "# The different indices in the parameters list correspond to different physical paramters\n",
    "sigma_coeff = parameters[0]\n",
    "sigma_exp = parameters[1]\n",
    "size_exp = parameters[2]\n",
    "amax_coeff = parameters[3]\n",
    "amax_exp = parameters[4]\n",
    "d2g_coeff = parameters[5]\n",
    "d2g_exp = parameters[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testparameters =[\n",
    "    7.0,\n",
    "    0.730,\n",
    "    0.558,\n",
    "    0.017,\n",
    "    0.625,\n",
    "    0.008,\n",
    "    0.050,\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a temporary folder in the current folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_directory = tempfile.TemporaryDirectory(dir='.')\n",
    "temp_path = temp_directory.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set some disk specific parameters (the commented-out values are the ones that were used before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mstar = 0.7 * MS\n",
    "# lstar = 1.56 * LS\n",
    "# tstar = 4266.00\n",
    "\n",
    "mstar = 10.**dh.sources.loc[disk]['log M_star/M_sun'] * M_sun\n",
    "lstar = 10.**dh.sources.loc[disk]['log L_star/L_sun'] * L_sun\n",
    "tstar = 10.**dh.sources.loc[disk]['log T_eff/ K']\n",
    "rstar = np.sqrt(lstar / (4 * np.pi * c.sigma_sb.cgs.value * tstar**4))\n",
    "PA = dh.sources.loc[disk]['PA']\n",
    "inc = dh.sources.loc[disk]['inc']\n",
    "dpc = dh.sources.loc[disk]['distance [pc]']\n",
    "\n",
    "nr = 100\n",
    "rin = 0.1 * au\n",
    "r_c = 300 * au  # ??\n",
    "rout = 400 * au  # 400au from avenhaus paper  #DSHARP Huang 2018 says 290 au\n",
    "alpha = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make the disklab 2D model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disk2d  = make_disklab2d_model(\n",
    "    testparameters,\n",
    "    mstar,\n",
    "    lstar,\n",
    "    tstar,\n",
    "    nr,\n",
    "    alpha,\n",
    "    rin,\n",
    "    rout,\n",
    "    r_c,\n",
    "    fname_opac_chopped,\n",
    "    show_plots=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'disk to star mass ratio = {disk2d.disk.mass / disk2d.disk.mstar:.2g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_radmc3d(disk2d, lam_opac, temp_path, show_plots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the mm continuum image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_mm_sim = Path(temp_path) / 'image_mm.fits'\n",
    "disklab.radmc3d.radmc3d(\n",
    "    f'image incl {inc} posang {PA-90} npix 500 lambda {lam_mm * 1e4} sizeau {2 * rout / au} secondorder  setthreads 1',\n",
    "    path=temp_path,\n",
    "    executable=str(radmc3d_exec)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radmc_image = Path(temp_path) / 'image.out'\n",
    "if radmc_image.is_file():\n",
    "    im_mm_sim = image.readImage(radmc_image)\n",
    "    radmc_image.replace(Path(temp_path) / 'image_mm.out')\n",
    "    im_mm_sim.writeFits(str(fname_mm_sim), dpc=dpc, coord='15h56m09.17658s -37d56m06.1193s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the fits files into imagecubes, and copy the beam information from the observation to the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_obs = imagecube(str(fname_mm_obs))\n",
    "\n",
    "iq_sim = imagecube(str(fname_mm_sim))\n",
    "iq_sim.bmaj, iq_sim.bmin, iq_sim.bpa = iq_obs.beam\n",
    "iq_sim.beamarea_arcsec = iq_sim._calculate_beam_area_arcsec()\n",
    "iq_sim.beamarea_str = iq_sim._calculate_beam_area_str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_cgs_sim = iq_sim.data * iq_sim.pix_per_beam / iq_sim.beamarea_str * 1e-23\n",
    "im_cgs_obs = iq_obs.data / iq_sim.beamarea_str * 1e-23\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(10, 5), sharex=True, sharey=True)\n",
    "vmin = RMS_jyb * 1e-23 / iq_obs.beamarea_str # the RMS from dsharp (Jy/beam) to CGS conversion\n",
    "vmax = 20 * vmin\n",
    "ax[0].imshow(im_cgs_sim, extent=iq_sim.extent, vmin=vmin, vmax=vmax, origin='lower')\n",
    "ax[1].imshow(im_cgs_obs, extent=iq_obs.extent, vmin=vmin, vmax=vmax, origin='lower')\n",
    "ax[0].set_xlim([2, -2])\n",
    "ax[0].set_ylim([-2, 2]);\n",
    "\n",
    "ax[0].axis('off')\n",
    "ax[1].axis('off')\n",
    "f.subplots_adjust(wspace=0)\n",
    "f.savefig('mm.pdf', transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mm_sim, y_mm_sim, dy_mm_sim = get_profile_from_fits(\n",
    "    str(fname_mm_sim),\n",
    "    clip=clip,\n",
    "    inc=inc, PA=PA,\n",
    "    z0=0.0,\n",
    "    psi=0.0,\n",
    "    beam=iq_obs.beam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we estimate the noise of the azimuthally averaged profile by dividing the RMS noise of the image by the approximate number of beams along the annulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin_avg = vmax / (2 * np.pi * x_mm_obs * np.sqrt(iq_obs.beam[0] * iq_obs.beam[1]) / iq_obs.beamarea_arcsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the azimuthal profile and error estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(dpi=150)\n",
    "ax.semilogy(x_mm_obs, y_mm_obs, label='ALMA data')\n",
    "ax.fill_between(x_mm_obs, y_mm_obs - dy_mm_obs, y_mm_obs + dy_mm_obs, alpha=0.5)\n",
    "\n",
    "ax.semilogy(x_mm_sim, y_mm_sim, label='model')\n",
    "ax.fill_between(x_mm_sim, y_mm_sim - dy_mm_sim, y_mm_sim + dy_mm_sim, alpha=0.5)\n",
    "\n",
    "#ax.fill_between(x_mm_obs, y_mm_obs - (vmax * err_est), y_mm_obs + (vmax * err_est), alpha=0.5)\n",
    "\n",
    "ax.axhline(vmin, c='0.5', ls='--', label='image RMS noise')\n",
    "ax.semilogy(x_mm_obs, vmin_avg, c='k', ls='--', label='expected RMS noise of profile')\n",
    "\n",
    "ax.semilogy(x_mm_obs, np.maximum(y_mm_obs, vmin_avg), c='k', ls='-')\n",
    "\n",
    "ax.set_xlim(1.5, 2.5);\n",
    "ax.set_ylim(5e-17, 1e-13)\n",
    "ax.set_xlabel('r [arcsec]')\n",
    "ax.set_ylabel('Intensity [erg/(s cm$^2$ Hz sr)]')\n",
    "ax.legend(fontsize='small')\n",
    "f.savefig('profile_mm.pdf', transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_max = max(len(x_mm_obs), len(x_mm_sim))\n",
    "\n",
    "x_mm_sim = x_mm_sim[:i_max]\n",
    "y_mm_sim = y_mm_sim[:i_max]\n",
    "x_mm_obs = x_mm_obs[:i_max]\n",
    "y_mm_obs = y_mm_obs[:i_max]\n",
    "\n",
    "if not np.allclose(x_mm_sim, x_mm_obs):\n",
    "    raise AssertionError('observed and simulated radial profile grids are not equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the log probability for the mm here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prob_mm = -0.5 * np.sum((np.interp(observed_radius, radial / 158,\n",
    "                                       radial_profile) - observed_intensity)**2 / (observed_intensity_error**2)) / len(observed_radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scattered light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUT OUT OPACITIES PART 2\n",
    "from disklab.radmc3d import write\n",
    "import dsharp_opac as opacity\n",
    "\n",
    "#for p in Path(temp_path).glob('dustkappa_*.inp'):\n",
    "#    p.unlink()\n",
    "\n",
    "for i_grain in range(n_a):\n",
    "    opacity.write_radmc3d_scatmat_file(i_grain, opac_dict, f'{i_grain}', path=temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(temp_path) / 'dustopac.inp', 'w') as f:\n",
    "    write(f, '2               Format number of this file')\n",
    "    write(f, '{}              Nr of dust species'.format(n_a))\n",
    "\n",
    "    for i_grain in range(n_a):\n",
    "        write(f, '============================================================================')\n",
    "        write(f, '10               Way in which this dust species is read')\n",
    "        write(f, '0               0=Thermal grain')\n",
    "        write(f, '{}              Extension of name of dustscatmat_***.inp file'.format(i_grain))\n",
    "\n",
    "    write(f, '----------------------------------------------------------------------------')\n",
    "\n",
    "# image calculation\n",
    "disklab.radmc3d.radmc3d(f'image incl {inc} posang {PA-90} npix 500 lambda {lam_sca / 1e-4} sizeau {2 * rout / au} setthreads 4', path=temp_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_sca_sim = Path(temp_path) / 'image_sca.fits'\n",
    "if (Path(temp_path) / 'image.out').is_file():\n",
    "    (Path(temp_path) / 'image.out').replace(fname_sca_sim.with_suffix('.out'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = image.readImage(fname_sca_sim.with_suffix('.out'))\n",
    "im.writeFits(str(fname_sca_sim), dpc=dpc, coord='15h56m09.17658s -37d56m06.1193s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_obs = imagecube(str(fname_sca_obs))\n",
    "iq_sim = imagecube(str(fname_sca_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sca_sim, y_sca_sim, dy_sca_sim = get_profile_from_fits(\n",
    "    str(fname_sca_sim),\n",
    "    clip=clip,\n",
    "    inc=inc, PA=PA,\n",
    "    z0=z0,\n",
    "    psi=psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.semilogy(x_sca_obs, y_sca_obs)\n",
    "ax.fill_between(x_sca_obs, y_sca_obs - dy_sca_obs, y_sca_obs + dy_sca_obs, alpha=0.5)\n",
    "\n",
    "ax.semilogy(x_sca_sim, y_sca_sim)\n",
    "ax.fill_between(x_sca_sim, y_sca_sim - dy_sca_sim, y_sca_sim + dy_sca_sim, alpha=0.5)\n",
    "\n",
    "ax.set_ylim(1e-17, 1e-13);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_cgs_sim = iq_sim.data\n",
    "im_cgs_obs = iq_obs.data\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(10, 5), sharex=True, sharey=True)\n",
    "vmin = 5e-8\n",
    "vmax = 20 * vmin\n",
    "ax[0].imshow(im_cgs_sim, extent=iq_sim.extent, vmin=vmin, vmax=vmax, origin='lower')\n",
    "ax[1].imshow(im_cgs_obs, extent=iq_obs.extent, vmin=vmin, vmax=vmax, origin='lower')\n",
    "ax[0].set_xlim([2, -2])\n",
    "ax[0].set_ylim([-2, 2])\n",
    "\n",
    "ax[0].axis('off')\n",
    "ax[1].axis('off')\n",
    "f.subplots_adjust(wspace=0)\n",
    "f.savefig('sca.pdf', transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "\n",
    "- [x] need to bring the mm profiles on the same scale to compare \n",
    "- [ ] figure out units of scattered light image (flux-calibrated?)\n",
    "- [ ] implement \"40 mas beam\" for the weighting of the SPHERE profiles\n",
    "- [ ] figure out how to handle the noisy parts\n",
    "- [ ] calculate the logP from the profiles\n",
    "- [ ] figure out how to treat the SPHERE image asymmetry (forward scattering)\n",
    "- [ ] test effect of porosity on asymmetry\n",
    "- [ ] whatever is below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_max = min(len(x_sca_obs), len(x_sca_sim))\n",
    "\n",
    "x_sca_sim = x_sca_sim[:i_max]\n",
    "y_sca_sim = y_sca_sim[:i_max]\n",
    "x_sca_obs = x_sca_obs[:i_max]\n",
    "y_sca_obs = y_sca_obs[:i_max]\n",
    "\n",
    "if not np.allclose(x_sca_sim, x_sca_obs):\n",
    "    raise AssertionError('observed and simulated radial profile grids are not equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate $\\log P$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prob_scat = -0.5 * np.nansum((np.interp(x, sim_x, sim_profile) - profile)**2 / (profile_err**2)) / len(x)\n",
    "\n",
    "# adding the two log probs and then multiplying by a large factor in order to make the MCMC more sensitive to changes\n",
    "log_prob = (log_prob_mm + log_prob_scat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "**Here comes the rest of `MCMC_parallelized.py`, not cleaned up yet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('step1')\n",
    "\n",
    "# Parallelizing the simluation and running it for 250 iterations\n",
    "with Pool(processes=100) as pool:\n",
    "    sampler1 = emcee.EnsembleSampler(nwalkers, ndim, logprob, args=[profile, profile_err, x_arcsec], pool=pool)\n",
    "    sampler1.run_mcmc(p0, 250)\n",
    "\n",
    "print(sampler1.iteration)    \n",
    "\n",
    "print('step2')\n",
    "sampler2 = deepcopy(sampler1)\n",
    "sampler2.log_prob_fn = None\n",
    "with open('sampler.pickle', 'wb') as fid:\n",
    "    pickle.dump(sampler2, fid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
