{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting IM Lup\n",
    "\n",
    "This code runs the MCMC simulation to calculate the best fit parameters for the disk. It uses the logprob function from logprob_parallel.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import astropy.units as u\n",
    "import emcee\n",
    "\n",
    "from imgcube import imagecube\n",
    "import dsharp_helper as dh\n",
    "import dsharp_opac as opacity\n",
    "\n",
    "from logprob_parallel import logprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipsy.utils import get_interfaces_from_log_cell_centers\n",
    "from dipsy import get_powerlaw_dust_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import disklab\n",
    "\n",
    "au = c.au.cgs.value\n",
    "M_sun = c.M_sun.cgs.value\n",
    "L_sun = c.L_sun.cgs.value\n",
    "R_sun = c.R_sun.cgs.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALMA data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set the disk name and get some disk properties from DSHARP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disk = 'IMLup'\n",
    "\n",
    "fname_mm_obs = dh.get_datafile(disk)\n",
    "PA = dh.sources.loc[disk]['PA']\n",
    "inc = dh.sources.loc[disk]['inc']\n",
    "distance = dh.sources.loc[disk]['distance [pc]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the observed mm profile from DSHARP and determine a radial profile with `imagecube` which is used as an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mm_obs = imagecube(fname_mm_obs, clip=2.5)\n",
    "\n",
    "x_as_obs, y_obs, dy_obs = data_mm_obs.radial_profile(inc=inc, PA=PA)\n",
    "\n",
    "profile_mm_obs = (y_obs * u.Jy / data_mm_obs.beam_area_str).cgs.value\n",
    "profile_mm_obs_err = (dy_obs * u.Jy / data_mm_obs.beam_area_str).cgs.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.semilogy(x_as_obs, profile_mm_obs)\n",
    "ax.fill_between(x_as_obs, profile_mm_obs - profile_mm_obs_err, profile_mm_obs + profile_mm_obs_err, alpha=0.5)\n",
    "ax.set_ylim(bottom=1e-16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opacities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the wavelength, size, and angle grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lam = 200\n",
    "n_a = 15\n",
    "n_theta = 100\n",
    "lam_opac = np.logspace(-5, 1, n_lam)\n",
    "a_opac = np.logspace(-5, 1, n_a)\n",
    "\n",
    "if n_theta // 2 == n_theta / 2:\n",
    "    n_theta += 1\n",
    "    print(f'n_theta needs to be odd, will set it to {n_theta}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate opacities and store them in a local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get optical constants and material density\n",
    "opac_fname = 'dustkappa_IMLUP'\n",
    "opac_fname = Path(opac_fname + '.npz')\n",
    "diel_const, rho_s = opacity.get_dsharp_mix()\n",
    "\n",
    "run_opac = True\n",
    "\n",
    "if opac_fname.is_file():\n",
    "    with np.load(opac_fname) as fid:\n",
    "        opac_dict = {k:v for k,v in fid.items()}\n",
    "    if (\n",
    "        (len(opac_dict['a']) == n_a) and\n",
    "        np.allclose(opac_dict['a'], a_opac) and\n",
    "        (len(opac_dict['lam']) == n_lam) and\n",
    "        np.allclose(opac_dict['lam'], lam_opac) and\n",
    "        (len(opac_dict['theta']) == n_theta) and\n",
    "        (opac_dict['rho_s'] == rho_s)\n",
    "        ):\n",
    "        print(f'reading from file {opac_fname}')\n",
    "        run_opac = False\n",
    "\n",
    "if run_opac:\n",
    "    # call the Mie calculation & store the opacity in a npz file\n",
    "    opac_dict = opacity.get_smooth_opacities(\n",
    "        a_opac,\n",
    "        lam_opac,\n",
    "        rho_s=rho_s,\n",
    "        diel_const=diel_const,\n",
    "        extrapolate_large_grains=False,\n",
    "        n_angle=(n_theta + 1) //2)\n",
    "\n",
    "    print(f'writing opacity to {opac_fname} ... ', end='', flush=True)\n",
    "    opacity.write_disklab_opacity(opac_fname, opac_dict)\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part chops the very-forward scattering part of the phase function. This part is basically the same as no scattering, but are treated by the code as a scattering event. By cutting this part out of the phase function, we avoid those non-scattering scattering events. This needs to recalculate $\\kappa_{sca}$ and $g$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 4 * np.pi / 3 * rho_s * a_opac**3\n",
    "\n",
    "k_abs = opac_dict['k_abs']\n",
    "k_sca = opac_dict['k_sca']\n",
    "S1 = opac_dict['S1']\n",
    "S2 = opac_dict['S2']\n",
    "theta = opac_dict['theta']\n",
    "g = opac_dict['g']\n",
    "\n",
    "zscat = opacity.calculate_mueller_matrix(lam_opac, m, S1, S2, theta=theta, k_sca=k_sca)['zscat']\n",
    "\n",
    "chopforward = 3\n",
    "zscat_nochop = np.zeros((n_a, n_lam, n_theta, 6))\n",
    "kscat_nochop = np.zeros((n_a, n_lam))\n",
    "g_nochop = np.zeros((n_a, n_lam))\n",
    "\n",
    "for grain in range(n_a):\n",
    "    for i in range(n_lam):\n",
    "        #\n",
    "        # Now loop over the grain sizes\n",
    "        #\n",
    "        if chopforward > 0:\n",
    "            iang = np.where(theta < chopforward)\n",
    "            if theta[0] == 0.0:\n",
    "                iiang = np.max(iang) + 1\n",
    "            else:\n",
    "                iiang = np.min(iang) - 1\n",
    "            zscat_nochop[grain, i, :, :] = zscat[grain, i, :, :]  # Backup\n",
    "            kscat_nochop[grain, i] = k_sca[grain, i]      # Backup\n",
    "            g_nochop[grain, i] = g[grain, i]\n",
    "            zscat[grain, i, iang, :] = zscat[grain, i, iiang, :]\n",
    "            mu = np.cos(theta * np.pi / 180.)\n",
    "            dmu = np.abs(mu[1:n_theta] - mu[0:(n_theta - 1)])\n",
    "            zav = 0.5 * (zscat[grain, i, 1:n_theta, 0] + zscat[grain, i, 0:n_theta - 1, 0])\n",
    "            dum = 0.5 * zav * dmu\n",
    "            sum = dum.sum() * 4 * np.pi\n",
    "            k_sca[grain, i] = sum\n",
    "\n",
    "            mu_2 = 0.5 * (np.cos(theta[1:n_theta] * np.pi / 180.) + np.cos(theta[0:n_theta - 1] * np.pi / 180.))\n",
    "            P_mu = 0.5 * ((2 * np.pi * zscat[grain, i, 1:n_theta, 0] / k_sca[grain, i]) + (2 * np.pi * zscat[grain, i, 0:n_theta - 1, 0] / k_sca[grain, i]))\n",
    "            g[grain, i] = np.sum(P_mu * mu_2 * dmu)\n",
    "\n",
    "opac_dict['zscat'] = zscat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot an example of a phase function before and after the chopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_grain = a_opac.searchsorted(0.01 * 2 * np.pi)\n",
    "i_lam = lam_opac.searchsorted(1e-4)\n",
    "\n",
    "_ang = opac_dict['theta'] * np.pi / 180\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.semilogy(opac_dict['theta'], zscat[i_grain, i_lam, :, 0], label='Z11 (chopped)');\n",
    "ax.semilogy(opac_dict['theta'], zscat_nochop[i_grain, i_lam, :, 0], label='Z11 (original)', ls='--');\n",
    "ax.set_xlim(0, 50)\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emcee part\n",
    "\n",
    "here we define some inputs and initial parameter sets for the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining number of walkers\n",
    "nwalkers = 25\n",
    "ndim     = 7\n",
    "\n",
    "# setting the priors for some parameters instead of letting them be uniform randoms between (0.1)\n",
    "\n",
    "sigma_coeff_0   = 10**((np.random.rand(nwalkers)-0.5)*4)\n",
    "others_0        = np.random.rand(ndim-3,nwalkers)\n",
    "d2g_coeff_0     = (np.random.rand(nwalkers)+0.5) / 100\n",
    "d2g_exp_0       = (np.random.rand(nwalkers)-0.5) \n",
    "\n",
    "# the input matrix of priors\n",
    "p0 = np.vstack((sigma_coeff_0,others_0, d2g_coeff_0, d2g_exp_0)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logprob testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = p0[0, :]\n",
    "# The different indices in the parameters list correspond to different physical paramters\n",
    "sigma_coeff = parameters[0]\n",
    "sigma_exp = parameters[1]\n",
    "size_exp = parameters[2]\n",
    "amax_coeff = parameters[3]\n",
    "amax_exp = parameters[4]\n",
    "d2g_coeff = parameters[5]\n",
    "d2g_exp = parameters[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a temporary folder in the current folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_directory = tempfile.TemporaryDirectory(dir='.')\n",
    "temp_path = temp_directory.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set some disk specific parameters (the commented-out values are the ones that were used before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mstar = 0.7 * MS\n",
    "mstar = 10.**dh.sources.loc[disk]['log M_star/M_sun'] * M_sun\n",
    "\n",
    "# lstar = 1.56 * LS\n",
    "lstar = 10.**dh.sources.loc[disk]['log L_star/L_sun'] * L_sun\n",
    "\n",
    "# tstar = 4266.00\n",
    "tstar = 10.**dh.sources.loc[disk]['log T_eff/ K']\n",
    "\n",
    "rstar = np.sqrt(lstar / (4 * np.pi * c.sigma_sb.cgs.value * tstar**4))\n",
    "\n",
    "nr = 100\n",
    "rin = 0.1 * au\n",
    "r_c = 300 * au  # ??\n",
    "rout = 400 * au  # 400au from avenhaus paper  #DSHARP Huang 2018 says 290 au\n",
    "alpha = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PA = dh.sources.loc[disk]['PA']\n",
    "inc = dh.sources.loc[disk]['inc']\n",
    "dpc = dh.sources.loc[disk]['distance [pc]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make the disklab 2D model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opac_params = ['dustcomponents', {'method': 'simplemixing'}]\n",
    "\n",
    "d = disklab.DiskRadialModel(mstar=mstar, lstar=lstar, tstar=tstar, nr=nr, alpha=alpha, rin=rin, rout=rout)\n",
    "\n",
    "d.make_disk_from_simplified_lbp(sigma_coeff, r_c, sigma_exp)\n",
    "\n",
    "if d.mass / mstar > 0.2:\n",
    "    #return -np.inf\n",
    "    warnings.warn('Disk mass is unreasonably high: M_disk / Mstar = {d.mass/mstar:.2g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2g = d2g_coeff * ((d.r / au)**d2g_exp)\n",
    "a_max = amax_coeff * (d.r/au)**(-amax_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_i = get_interfaces_from_log_cell_centers(a_opac)\n",
    "a, a_i, sig_da = get_powerlaw_dust_distribution(d.sigma * d2g, np.minimum(a_opac[-1], a_max), q=4 - size_exp, na=n_a, a0=a_i[0], a1=a_i[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "\n",
    "ax.contourf(d.r / au, a_opac, np.log10(sig_da.T))\n",
    "\n",
    "ax.loglog(d.r / au, a_max, label='a_max')\n",
    "ax.loglog(d.r / au, d2g, label='d2g')\n",
    "\n",
    "ax.set_ylim(1e-5, 1e0)\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _sig, _a in zip(np.transpose(sig_da), a_opac):\n",
    "    d.add_dust(agrain=_a, xigrain=rho_s, dtg=_sig / d.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the opacity from the previously calculated opacity table\n",
    "for dust in d.dust:\n",
    "    dust.grain.read_opacity(str(opac_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the mean opacities\n",
    "d.meanopacitymodel = opac_params\n",
    "d.compute_mean_opacity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.loglog(d.r / au, d.mean_opacity_planck)\n",
    "ax.loglog(d.r / au, d.mean_opacity_rosseland)\n",
    "\n",
    "def movingaverage(interval, window_size):\n",
    "    window = np.ones(int(window_size)) / float(window_size)\n",
    "    return np.convolve(interval, window, 'same')\n",
    "\n",
    "d.mean_opacity_planck[7:-7] = movingaverage(d.mean_opacity_planck, 10)[7:-7]\n",
    "d.mean_opacity_rosseland[7:-7] = movingaverage(d.mean_opacity_rosseland, 10)[7:-7]\n",
    "\n",
    "ax.loglog(d.r / au, d.mean_opacity_planck, 'C0--')\n",
    "ax.loglog(d.r / au, d.mean_opacity_rosseland, 'C1--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.loglog(d.r / au, d.tmid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a 2D model out of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in range(100):\n",
    "    d.compute_hsurf()\n",
    "    d.compute_flareindex()\n",
    "    d.compute_flareangle_from_flareindex(inclrstar=True)\n",
    "    d.compute_disktmid(keeptvisc=False)\n",
    "    d.compute_cs_and_hp()\n",
    "\n",
    "disk2d = disklab.Disk2D(\n",
    "    disk=d,\n",
    "    meanopacitymodel=d.meanopacitymodel,\n",
    "    nz=100)\n",
    "\n",
    "# snippet vertstruc 2d_1\n",
    "for vert in disk2d.verts:\n",
    "    vert.iterate_vertical_structure()\n",
    "disk2d.radial_raytrace()\n",
    "for vert in disk2d.verts:\n",
    "    vert.solve_vert_rad_diffusion()\n",
    "    vert.tgas = (vert.tgas**4 + 15**4)**(1 / 4)\n",
    "    for dust in vert.dust:\n",
    "        dust.compute_settling_mixing_equilibrium()\n",
    "\n",
    "rmcd = disklab.radmc3d.get_radmc3d_arrays(disk2d, showplots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the radmc3d data\n",
    "\n",
    "# nphi = rmcd['nphi']\n",
    "ri = rmcd['ri']\n",
    "thetai = rmcd['thetai']\n",
    "phii = rmcd['phii']\n",
    "nr = rmcd['nr']\n",
    "# nth = rmcd['nth']\n",
    "# nphi = rmcd['nphi']\n",
    "rho = rmcd['rho']\n",
    "\n",
    "# we need to tile this for each species\n",
    "\n",
    "rmcd_temp = rmcd['temp'][:, :, None] * np.ones(n_a)[None, None, :]\n",
    "\n",
    "# Define the wavelength grid for the radiative transfer\n",
    "\n",
    "lam_mic = lam_opac * 1e4\n",
    "\n",
    "# Write the `RADMC3D` input\n",
    "\n",
    "disklab.radmc3d.write_stars_input(d, lam_mic, path=temp_path)\n",
    "disklab.radmc3d.write_grid(ri, thetai, phii, mirror=False, path=temp_path)\n",
    "disklab.radmc3d.write_dust_density(rmcd_temp, fname='dust_temperature.dat', path=temp_path, mirror=False)\n",
    "disklab.radmc3d.write_dust_density(rho, mirror=False, path=temp_path)\n",
    "disklab.radmc3d.write_wavelength_micron(lam_mic, path=temp_path)\n",
    "disklab.radmc3d.write_opacity(disk2d, path=temp_path)\n",
    "disklab.radmc3d.write_radmc3d_input(\n",
    "    {'scattering_mode': 5, 'scattering_mode_max': 5, 'nphot': 10000000},\n",
    "    path=temp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate the mm continuum image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_mm_sim = Path(temp_path) / 'image.fits'\n",
    "lam_obs = 0.125\n",
    "rd = 300 * au\n",
    "disklab.radmc3d.radmc3d(\n",
    "    f'image incl 47.5 posang -144.4 npix 500 lambda {lam_obs * 1e4} sizeau {4 * rd / au} secondorder  setthreads 1',\n",
    "    path=temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = disklab.radmc3d.read_image(filename=str(fname_mm_sim.with_suffix('.out')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from radmc3dPy import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = image.readImage(str(fname_mm_sim.with_suffix('.out')))\n",
    "im.writeFits(str(fname_mm_sim), dpc=dpc, coord='15h56m09.17658s -37d56m06.1193s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mm_sim = imagecube(str(fname_mm_sim), clip=2.5)\n",
    "\n",
    "x_as_sim, y_sim, dy_sim = data_mm_sim.radial_profile(inc=inc, PA=PA)\n",
    "\n",
    "profile_mm_sim = (y_sim * u.Jy / data_mm_sim.beam_area_str).cgs.value\n",
    "profile_mm_sim_err = (dy_sim * u.Jy / data_mm_sim.beam_area_str).cgs.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.semilogy(x_as_obs, profile_mm_obs)\n",
    "ax.fill_between(x_as_obs, profile_mm_obs - profile_mm_obs_err, profile_mm_obs + profile_mm_obs_err, alpha=0.5)\n",
    "\n",
    "ax.semilogy(x_as_sim, profile_mm_sim)\n",
    "ax.fill_between(x_as_sim, profile_mm_sim - profile_mm_sim_err, profile_mm_sim + profile_mm_sim_err, alpha=0.5)\n",
    "\n",
    "ax.set_ylim(bottom=1e-16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.imshow(np.log10(im.image[:, :, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining the resultant radial intensity profile and subsequent calculation\n",
    "# of the logprob from this image divided by number of observation\n",
    "\n",
    "radial_profile = []\n",
    "radial = []\n",
    "for x, y in zip(range(0, 251, 1), range(249, 500, 1)):\n",
    "    radial_profile.append(\n",
    "        im.image[y][int(round(249 + x * np.tan(0.6213372)))])\n",
    "    radial.append(np.sqrt(\n",
    "        (im.x[int(round(249 + x * np.tan(0.6213372)))] / au)**2 + (im.y[y] / au)**2))\n",
    "radial = np.asarray(radial)\n",
    "radial_profile = np.asarray(radial_profile)\n",
    "\n",
    "radial_profile = radial_profile[radial > 158]\n",
    "radial = radial[radial > 158]\n",
    "\n",
    "observed_intensity = observed_intensity[observed_radius > 1]\n",
    "observed_intensity_error = observed_intensity_error[observed_radius > 1]\n",
    "observed_radius = observed_radius[observed_radius > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prob_mm = -0.5 * np.sum((np.interp(observed_radius, radial / 158,\n",
    "                                       radial_profile) - observed_intensity)**2 / (observed_intensity_error**2)) / len(observed_radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scattered light"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deproject the scattered light image, we will need to know where the scattering surface is. This is based on the Avenhaus et al. 2018 paper. In `imagecube` this surface can be defined with `z0` and `psi` such that its height $z$ is at\n",
    "\n",
    "$\\mathsf{z = z0 \\, \\left(\\frac{r}{arcsec}\\right)^{psi}}\\, arcsec$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0 = 0.2\n",
    "psi = 1.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUT OUT OPACITIES PART 2\n",
    "from disklab.radmc3d import write\n",
    "\n",
    "for p in Path(temp_path).glob('dustkappa_*.inp'):\n",
    "    p.unlink()\n",
    "\n",
    "for i_grain in range(n_a):\n",
    "    opacity.write_radmc3d_scatmat_file(i_grain, opac_dict, f'{i_grain}', path=temp_path)\n",
    "\n",
    "with open(Path(temp_path) / 'dustopac.inp', 'w') as f:\n",
    "    write(f, '2               Format number of this file')\n",
    "    write(f, '{}              Nr of dust species'.format(len(agrains)))\n",
    "\n",
    "    for x in agrains:\n",
    "        i_grain = agrains.searchsorted(x)\n",
    "        write(f, '============================================================================')\n",
    "        write(f, '10               Way in which this dust species is read')\n",
    "        write(f, '0               0=Thermal grain')\n",
    "        write(f, '{}              Extension of name of dustscatmat_***.inp file'.format(i_grain))\n",
    "\n",
    "    write(f, '----------------------------------------------------------------------------')\n",
    "\n",
    "# image calculation\n",
    "rd = 250 * au\n",
    "radmc3d.radmc3d(f'image incl {inc} posang {PA-90} npix 500 lambda 1.65 sizeau 1000 setthreads 4', path=temp_path)\n",
    "\n",
    "fname_sca_img = Path(temp_path) / 'image.fits'\n",
    "im = image.readImage(fname_sca_img.with_suffix('.out'))\n",
    "im.writeFits(fname_sca_img, dpc=dpc, coord='15h56m09.17658s -37d56m06.1193s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "\n",
    "- check image brightness conversion of the sphere image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read scattered light observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_sca_obs = 'Qphi_IMLup.fits'\n",
    "\n",
    "clip = 3.0 # at how many arcsec to clip the image data\n",
    "\n",
    "# fix the header of the sphere image\n",
    "hdulist = fits.open(fname_sca_obs)\n",
    "hdu0 = hdulist[0]\n",
    "\n",
    "hdu0.header['cdelt1'] = -3.405e-06\n",
    "hdu0.header['cdelt2'] = 3.405e-06\n",
    "hdu0.header['crpix1'] = hdu0.header['naxis1'] // 2 + 1\n",
    "hdu0.header['crpix2'] = hdu0.header['naxis2'] // 2 + 1\n",
    "hdu0.header['crval1'] = 0.0\n",
    "hdu0.header['crval2'] = 0.0\n",
    "hdu0.header['crval3'] = 1.65e-4\n",
    "\n",
    "# read it with imagecube and derive a radial profile\n",
    "\n",
    "data = imagecube(hdulist, clip=clip)\n",
    "\n",
    "x, y, dy = data.radial_profile(inc=inc, PA=PA, z0=z0, psi=psi)\n",
    "\n",
    "# convert from Jy / beam to cgs\n",
    "\n",
    "profile_sca = (y * u.Jy / data.beam_area_str).cgs.value\n",
    "profile_sca_err = (dy * u.Jy / data.beam_area_str).cgs.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read scattered light RADMC3D image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the profile from scattered light image using imagecube\n",
    "sim_data = imagecube(fname_sca_img, clip=clip)\n",
    "\n",
    "sim_x, sim_y, sim_dy = sim_data.radial_profile(inc=inc, PA=PA, z0=z0, psi=psi)\n",
    "\n",
    "sim_profile = (sim_y * u.Jy / sim_data.beam_area_str).cgs.value\n",
    "sim_profile_err = (sim_dy * u.Jy / sim_data.beam_area_str).cgs.value\n",
    "\n",
    "profile = profile[x > 1]\n",
    "profile_err = profile_err[x > 1]\n",
    "x = x[x > 1]\n",
    "\n",
    "sim_profile = sim_profile[sim_x > 1]\n",
    "sim_profile_err = sim_profile_err[sim_x > 1]\n",
    "sim_x = sim_x[sim_x > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate $\\log P$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prob_scat = -0.5 * np.nansum((np.interp(x, sim_x, sim_profile) - profile)**2 / (profile_err**2)) / len(x)\n",
    "\n",
    "# adding the two log probs and then multiplying by a large factor in order to make the MCMC more sensitive to changes\n",
    "log_prob = (log_prob_mm + log_prob_scat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "**Here comes the rest of `MCMC_parallelized.py`, not cleaned up yet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('step1')\n",
    "\n",
    "# Parallelizing the simluation and running it for 250 iterations\n",
    "with Pool(processes=100) as pool:\n",
    "    sampler1 = emcee.EnsembleSampler(nwalkers, ndim, logprob, args=[profile, profile_err, x_arcsec], pool=pool)\n",
    "    sampler1.run_mcmc(p0, 250)\n",
    "\n",
    "print(sampler1.iteration)    \n",
    "\n",
    "print('step2')\n",
    "sampler2 = deepcopy(sampler1)\n",
    "sampler2.log_prob_fn = None\n",
    "with open('sampler.pickle', 'wb') as fid:\n",
    "    pickle.dump(sampler2, fid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
