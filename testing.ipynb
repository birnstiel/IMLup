{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting IM Lup\n",
    "\n",
    "This code runs the MCMC simulation to calculate the best fit parameters for the disk. It uses the logprob function from logprob_parallel.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import astropy.units as u\n",
    "import emcee\n",
    "\n",
    "import dsharp_helper as dh\n",
    "import disklab\n",
    "from imgcube import imagecube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import get_profile_from_fits\n",
    "from helper_functions import make_opacs\n",
    "from helper_functions import chop_forward_scattering\n",
    "from helper_functions import make_disklab2d_model\n",
    "from helper_functions import write_radmc3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from radmc3dPy import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "au = c.au.cgs.value\n",
    "M_sun = c.M_sun.cgs.value\n",
    "L_sun = c.L_sun.cgs.value\n",
    "R_sun = c.R_sun.cgs.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALMA data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set the disk name and get some disk properties from DSHARP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disk = 'IMLup'\n",
    "fname_mm_obs = dh.get_datafile(disk)\n",
    "\n",
    "PA = dh.sources.loc[disk]['PA']\n",
    "inc = dh.sources.loc[disk]['inc']\n",
    "distance = dh.sources.loc[disk]['distance [pc]']\n",
    "\n",
    "clip = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mm_obs, y_mm_obs, dy_mm_obs = get_profile_from_fits(\n",
    "    fname_mm_obs,\n",
    "    clip=clip,\n",
    "    show_plots=True,\n",
    "    inc=inc, PA=PA,\n",
    "    z0=0.0,\n",
    "    psi=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opacities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the wavelength, size, and angle grids\n",
    "\n",
    "then calculate opacities and store them in a local file, if it doesn't exist yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lam = 200 # number of wavelength points\n",
    "n_a = 15 # number of particle sizes\n",
    "n_theta = 101 # number of angles in the scattering phase function\n",
    "fname_opac = 'dustkappa_IMLUP.npz'\n",
    "\n",
    "# wavelength and particle sizes grids\n",
    "\n",
    "lam_opac = np.logspace(-5, 1, n_lam)\n",
    "a_opac = np.logspace(-5, 1, n_a)\n",
    "\n",
    "# make opacities if necessary\n",
    "\n",
    "opac_dict = make_opacs(a_opac, lam_opac, fname=fname_opac, constants=None, n_theta=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part chops the very-forward scattering part of the phase function. This part is basically the same as no scattering, but are treated by the code as a scattering event. By cutting this part out of the phase function, we avoid those non-scattering scattering events. This needs to recalculate $\\kappa_{sca}$ and $g$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_sca_nochop = opac_dict['k_sca']\n",
    "g_nochop = opac_dict['g']\n",
    "\n",
    "zscat, zscat_nochop, k_sca, g = chop_forward_scattering(opac_dict)\n",
    "\n",
    "opac_dict['k_sca'] = k_sca\n",
    "opac_dict['zscat'] = zscat\n",
    "opac_dict['g'] = g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot an example of a phase function before and after the chopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_grain = a_opac.searchsorted(0.01 * 2 * np.pi)\n",
    "i_lam = lam_opac.searchsorted(1e-4)\n",
    "\n",
    "_ang = opac_dict['theta'] * np.pi / 180\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.semilogy(opac_dict['theta'], zscat[i_grain, i_lam, :, 0], label='Z11 (chopped)');\n",
    "ax.semilogy(opac_dict['theta'], zscat_nochop[i_grain, i_lam, :, 0], label='Z11 (original)', ls='--');\n",
    "ax.set_xlim(0, 50)\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_abs = opac_dict['k_abs']\n",
    "# k_sca = opac_dict['k_sca']\n",
    "# S1 = opac_dict['S1']\n",
    "# S2 = opac_dict['S2']\n",
    "# theta = opac_dict['theta']\n",
    "# g = opac_dict['g']\n",
    "rho_s = opac_dict['rho_s']\n",
    "\n",
    "m = 4 * np.pi / 3 * rho_s * a_opac**3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emcee part\n",
    "\n",
    "here we define some inputs and initial parameter sets for the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining number of walkers\n",
    "nwalkers = 25\n",
    "ndim     = 7\n",
    "\n",
    "# setting the priors for some parameters instead of letting them be uniform randoms between (0.1)\n",
    "\n",
    "sigma_coeff_0   = 10**((np.random.rand(nwalkers)-0.5)*4)\n",
    "others_0        = np.random.rand(ndim-3,nwalkers)\n",
    "d2g_coeff_0     = (np.random.rand(nwalkers)+0.5) / 100\n",
    "d2g_exp_0       = (np.random.rand(nwalkers)-0.5) \n",
    "\n",
    "# the input matrix of priors\n",
    "p0 = np.vstack((sigma_coeff_0,others_0, d2g_coeff_0, d2g_exp_0)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logprob testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = p0[0, :]\n",
    "# The different indices in the parameters list correspond to different physical paramters\n",
    "sigma_coeff = parameters[0]\n",
    "sigma_exp = parameters[1]\n",
    "size_exp = parameters[2]\n",
    "amax_coeff = parameters[3]\n",
    "amax_exp = parameters[4]\n",
    "d2g_coeff = parameters[5]\n",
    "d2g_exp = parameters[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a temporary folder in the current folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_directory = tempfile.TemporaryDirectory(dir='.')\n",
    "temp_path = temp_directory.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set some disk specific parameters (the commented-out values are the ones that were used before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mstar = 0.7 * MS\n",
    "# lstar = 1.56 * LS\n",
    "# tstar = 4266.00\n",
    "\n",
    "mstar = 10.**dh.sources.loc[disk]['log M_star/M_sun'] * M_sun\n",
    "lstar = 10.**dh.sources.loc[disk]['log L_star/L_sun'] * L_sun\n",
    "tstar = 10.**dh.sources.loc[disk]['log T_eff/ K']\n",
    "rstar = np.sqrt(lstar / (4 * np.pi * c.sigma_sb.cgs.value * tstar**4))\n",
    "PA = dh.sources.loc[disk]['PA']\n",
    "inc = dh.sources.loc[disk]['inc']\n",
    "dpc = dh.sources.loc[disk]['distance [pc]']\n",
    "\n",
    "nr = 100\n",
    "rin = 0.1 * au\n",
    "r_c = 300 * au  # ??\n",
    "rout = 400 * au  # 400au from avenhaus paper  #DSHARP Huang 2018 says 290 au\n",
    "alpha = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make the disklab 2D model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disk2d  = make_disklab2d_model(\n",
    "    p0[0],\n",
    "    mstar,\n",
    "    lstar,\n",
    "    tstar,\n",
    "    nr,\n",
    "    alpha,\n",
    "    rin,\n",
    "    rout,\n",
    "    r_c,\n",
    "    fname_opac,\n",
    "    show_plots=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_radmc3d(disk2d, lam_opac, temp_path, show_plots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the mm continuum image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_mm_sim = Path(temp_path) / 'image.fits'\n",
    "lam_obs = 0.125\n",
    "rd = 600 * au\n",
    "disklab.radmc3d.radmc3d(\n",
    "    f'image incl 47.5 posang -144.4 npix 500 lambda {lam_obs * 1e4} sizeau {2 * rd / au} secondorder  setthreads 1',\n",
    "    path=temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_mm_sim = image.readImage(str(fname_mm_sim.with_suffix('.out')))\n",
    "im_mm_sim.writeFits(str(fname_mm_sim), dpc=dpc, coord='15h56m09.17658s -37d56m06.1193s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mm_sim, y_mm_sim, dy_mm_sim = get_profile_from_fits(\n",
    "    str(fname_mm_sim),\n",
    "    clip=clip,\n",
    "    inc=inc, PA=PA,\n",
    "    z0=0.0,\n",
    "    psi=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.semilogy(x_mm_obs, y_mm_obs)\n",
    "ax.fill_between(x_mm_obs, y_mm_obs - dy_mm_obs, y_mm_obs + dy_mm_obs, alpha=0.5)\n",
    "\n",
    "ax.semilogy(x_mm_sim, y_mm_sim)\n",
    "ax.fill_between(x_mm_sim, y_mm_sim - dy_mm_sim, y_mm_sim + dy_mm_sim, alpha=0.5)\n",
    "\n",
    "ax.set_ylim(bottom=1e-16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_mm_obs = imagecube(str(fname_mm_sim), clip=clip)\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(np.log10(im_mm_sim.image[:, :, 0]), extent=[-rd / au, rd / au, -rd / au, rd / au])\n",
    "ax[1].imshow(np.log10(im_mm_obs.data), extent=[im_mm_obs.xaxis[0], im_mm_obs.xaxis[-1], im_mm_obs.yaxis[0], im_mm_obs.yaxis[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prob_mm = -0.5 * np.sum((np.interp(observed_radius, radial / 158,\n",
    "                                       radial_profile) - observed_intensity)**2 / (observed_intensity_error**2)) / len(observed_radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scattered light"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deproject the scattered light image, we will need to know where the scattering surface is. This is based on the Avenhaus et al. 2018 paper. In `imagecube` this surface can be defined with `z0` and `psi` such that its height $z$ is at\n",
    "\n",
    "$\\mathsf{z = z0 \\, \\left(\\frac{r}{arcsec}\\right)^{psi}}\\, arcsec$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0 = 0.2\n",
    "psi = 1.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUT OUT OPACITIES PART 2\n",
    "from disklab.radmc3d import write\n",
    "\n",
    "for p in Path(temp_path).glob('dustkappa_*.inp'):\n",
    "    p.unlink()\n",
    "\n",
    "for i_grain in range(n_a):\n",
    "    opacity.write_radmc3d_scatmat_file(i_grain, opac_dict, f'{i_grain}', path=temp_path)\n",
    "\n",
    "with open(Path(temp_path) / 'dustopac.inp', 'w') as f:\n",
    "    write(f, '2               Format number of this file')\n",
    "    write(f, '{}              Nr of dust species'.format(len(agrains)))\n",
    "\n",
    "    for x in agrains:\n",
    "        i_grain = agrains.searchsorted(x)\n",
    "        write(f, '============================================================================')\n",
    "        write(f, '10               Way in which this dust species is read')\n",
    "        write(f, '0               0=Thermal grain')\n",
    "        write(f, '{}              Extension of name of dustscatmat_***.inp file'.format(i_grain))\n",
    "\n",
    "    write(f, '----------------------------------------------------------------------------')\n",
    "\n",
    "# image calculation\n",
    "rd = 250 * au\n",
    "radmc3d.radmc3d(f'image incl {inc} posang {PA-90} npix 500 lambda 1.65 sizeau 1000 setthreads 4', path=temp_path)\n",
    "\n",
    "fname_sca_img = Path(temp_path) / 'image.fits'\n",
    "im = image.readImage(fname_sca_img.with_suffix('.out'))\n",
    "im.writeFits(fname_sca_img, dpc=dpc, coord='15h56m09.17658s -37d56m06.1193s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "\n",
    "- check image brightness conversion of the sphere image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read scattered light observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_sca_obs = 'Qphi_IMLup.fits'\n",
    "\n",
    "clip = 3.0 # at how many arcsec to clip the image data\n",
    "\n",
    "# fix the header of the sphere image\n",
    "hdulist = fits.open(fname_sca_obs)\n",
    "hdu0 = hdulist[0]\n",
    "\n",
    "hdu0.header['cdelt1'] = -3.405e-06\n",
    "hdu0.header['cdelt2'] = 3.405e-06\n",
    "hdu0.header['crpix1'] = hdu0.header['naxis1'] // 2 + 1\n",
    "hdu0.header['crpix2'] = hdu0.header['naxis2'] // 2 + 1\n",
    "hdu0.header['crval1'] = 0.0\n",
    "hdu0.header['crval2'] = 0.0\n",
    "hdu0.header['crval3'] = 1.65e-4\n",
    "\n",
    "# read it with imagecube and derive a radial profile\n",
    "\n",
    "data = imagecube(hdulist, clip=clip)\n",
    "\n",
    "x, y, dy = data.radial_profile(inc=inc, PA=PA, z0=z0, psi=psi)\n",
    "\n",
    "# convert from Jy / beam to cgs\n",
    "\n",
    "profile_sca = (y * u.Jy / data.beam_area_str).cgs.value\n",
    "profile_sca_err = (dy * u.Jy / data.beam_area_str).cgs.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read scattered light RADMC3D image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the profile from scattered light image using imagecube\n",
    "sim_data = imagecube(fname_sca_img, clip=clip)\n",
    "\n",
    "sim_x, sim_y, sim_dy = sim_data.radial_profile(inc=inc, PA=PA, z0=z0, psi=psi)\n",
    "\n",
    "sim_profile = (sim_y * u.Jy / sim_data.beam_area_str).cgs.value\n",
    "sim_profile_err = (sim_dy * u.Jy / sim_data.beam_area_str).cgs.value\n",
    "\n",
    "profile = profile[x > 1]\n",
    "profile_err = profile_err[x > 1]\n",
    "x = x[x > 1]\n",
    "\n",
    "sim_profile = sim_profile[sim_x > 1]\n",
    "sim_profile_err = sim_profile_err[sim_x > 1]\n",
    "sim_x = sim_x[sim_x > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate $\\log P$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prob_scat = -0.5 * np.nansum((np.interp(x, sim_x, sim_profile) - profile)**2 / (profile_err**2)) / len(x)\n",
    "\n",
    "# adding the two log probs and then multiplying by a large factor in order to make the MCMC more sensitive to changes\n",
    "log_prob = (log_prob_mm + log_prob_scat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "**Here comes the rest of `MCMC_parallelized.py`, not cleaned up yet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('step1')\n",
    "\n",
    "# Parallelizing the simluation and running it for 250 iterations\n",
    "with Pool(processes=100) as pool:\n",
    "    sampler1 = emcee.EnsembleSampler(nwalkers, ndim, logprob, args=[profile, profile_err, x_arcsec], pool=pool)\n",
    "    sampler1.run_mcmc(p0, 250)\n",
    "\n",
    "print(sampler1.iteration)    \n",
    "\n",
    "print('step2')\n",
    "sampler2 = deepcopy(sampler1)\n",
    "sampler2.log_prob_fn = None\n",
    "with open('sampler.pickle', 'wb') as fid:\n",
    "    pickle.dump(sampler2, fid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
