{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting IM Lup\n",
    "\n",
    "This code runs the MCMC simulation to calculate the best fit parameters for the disk. It uses the logprob function from logprob_parallel.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import getpass\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import astropy.units as u\n",
    "import astropy.constants as c\n",
    "from astropy.io import fits\n",
    "import emcee\n",
    "\n",
    "import dsharp_helper as dh\n",
    "import dsharp_opac as do\n",
    "import disklab\n",
    "from gofish import imagecube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import get_profile_from_fits\n",
    "from helper_functions import get_normalized_profiles\n",
    "from helper_functions import make_opacs\n",
    "from helper_functions import chop_forward_scattering\n",
    "from helper_functions import make_disklab2d_model\n",
    "from helper_functions import write_radmc3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from radmc3dPy import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "au = c.au.cgs.value\n",
    "M_sun = c.M_sun.cgs.value\n",
    "L_sun = c.L_sun.cgs.value\n",
    "R_sun = c.R_sun.cgs.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if getpass.getuser() == 'birnstiel':\n",
    "    radmc3d_exec = Path('~/.bin/radmc3d').expanduser()\n",
    "else:\n",
    "    radmc3d_exec = Path('~/bin/radmc3d').expanduser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disk = 'IMLup'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disklab Grid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr = 100\n",
    "rin = 0.1 * au\n",
    "rout = 400 * au  # 400au from avenhaus paper  #DSHARP Huang 2018 says 290 au"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**physical parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_c = 300 * au  # ??\n",
    "alpha = 1e-3\n",
    "\n",
    "mstar = 10.**dh.sources.loc[disk]['log M_star/M_sun'] * M_sun\n",
    "lstar = 10.**dh.sources.loc[disk]['log L_star/L_sun'] * L_sun\n",
    "tstar = 10.**dh.sources.loc[disk]['log T_eff/ K']\n",
    "rstar = np.sqrt(lstar / (4 * np.pi * c.sigma_sb.cgs.value * tstar**4))\n",
    "\n",
    "PA = dh.sources.loc[disk]['PA']\n",
    "inc = dh.sources.loc[disk]['inc']\n",
    "dpc = dh.sources.loc[disk]['distance [pc]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ALMA data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_mm_obs = dh.get_datafile(disk)\n",
    "clip = 5\n",
    "lam_mm = 0.125\n",
    "RMS_jyb = 14e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sphere data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deproject the scattered light image, we will need to know where the scattering surface is. This is based on the Avenhaus et al. 2018 paper. In `imagecube` this surface can be defined with `z0` and `psi` such that its height $z$ is at\n",
    "\n",
    "$\\mathsf{z = z0 \\, \\left(\\frac{r}{arcsec}\\right)^{psi}}\\, arcsec$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disk surface parameters\n",
    "\n",
    "z0 = 0.2\n",
    "psi = 1.27\n",
    "\n",
    "# observed wavelength\n",
    "lam_sca = 1.65e-4\n",
    "\n",
    "# fname_sca_obs_orig = 'Qphi_IMLup.fits'\n",
    "fname_sca_obs_orig = 'IM_Lup_reducedRob_median_Hband_12.25mas.fits'\n",
    "\n",
    " # pixel size of the sphere image, converted to degree\n",
    "pixelsize = (12.5*u.mas).to('deg').value\n",
    "\n",
    "# the \"beam\" assumed in the radial profile calculation\n",
    "beam_sca = (0.040, 0.040, 0.0)\n",
    "\n",
    "# RMS of the observations\n",
    "RMS_sca = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALMA data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the radial profile from the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mm_obs, y_mm_obs, dy_mm_obs = get_profile_from_fits(\n",
    "    fname_mm_obs,\n",
    "    clip=clip,\n",
    "    inc=inc, PA=PA,\n",
    "    z0=0.0,\n",
    "    psi=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare against the DSHARP profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_prof = dh.get_profile(disk)\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.semilogy(x_mm_obs, y_mm_obs)\n",
    "ax.fill_between(x_mm_obs, y_mm_obs - dy_mm_obs, y_mm_obs + dy_mm_obs, alpha=0.5)\n",
    "\n",
    "ax.semilogy(ds_prof['r_as'], ds_prof['I_nu'])\n",
    "ax.fill_between(ds_prof['r_as'], ds_prof['I_nu_l'], ds_prof['I_nu_u'], alpha=0.5)\n",
    "\n",
    "ax.set_ylim(2e-17, 1e-13);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPHERE data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image does not contain all the required info, so we make a copy of the fits file and modify that one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_sca_obs = fname_sca_obs_orig.replace('.fits', '_mod.fits')\n",
    "shutil.copy(fname_sca_obs_orig, fname_sca_obs)\n",
    "\n",
    "fits.setval(fname_sca_obs, 'cdelt1', value=-pixelsize)\n",
    "fits.setval(fname_sca_obs, 'cdelt2', value=pixelsize)\n",
    "fits.setval(fname_sca_obs, 'crpix1', value=fits.getval(fname_sca_obs_orig, 'naxis1') // 2 - 0.5)\n",
    "fits.setval(fname_sca_obs, 'crpix2', value=fits.getval(fname_sca_obs_orig, 'naxis2') // 2 - 0.5)\n",
    "fits.setval(fname_sca_obs, 'crval1', value=0.0)\n",
    "fits.setval(fname_sca_obs, 'crval2', value=0.0)\n",
    "fits.setval(fname_sca_obs, 'crval3', value=1.65e-4)\n",
    "fits.setval(fname_sca_obs, 'BUNIT', value='JY/PIXEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read it with imagecube and derive profiles\n",
    "profiles_sca_obs = get_normalized_profiles(\n",
    "    fname_sca_obs,\n",
    "    clip=clip,\n",
    "    inc=inc,\n",
    "    PA=PA,\n",
    "    z0=z0,\n",
    "    psi=psi,\n",
    "    beam=beam_sca,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "\n",
    "for i, key in enumerate(profiles_sca_obs.keys()):\n",
    "    profile = profiles_sca_obs[key]\n",
    "    x = profile['x']\n",
    "    y = profile['y']\n",
    "    dy = profile['dy']\n",
    "    mask = profile['mask']\n",
    "\n",
    "    ax.semilogy(x, y, c=f'C{i}')\n",
    "    ax.fill_between(x, y - dy, y + dy, fc=f'C{i}', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opacities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the wavelength, size, and angle grids then calculate opacities and store them in a local file, if it doesn't exist yet.  \n",
    "**Careful, that takes of the order of >2h**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lam = 200 # number of wavelength points\n",
    "n_a = 15 # number of particle sizes\n",
    "n_theta = 181 # number of angles in the scattering phase function\n",
    "porosity = 0.3\n",
    "\n",
    "# wavelength and particle sizes grids\n",
    "\n",
    "lam_opac = np.logspace(-5, 1, n_lam)\n",
    "a_opac = np.logspace(-5, 1, n_a)\n",
    "\n",
    "# make opacities if necessary\n",
    "\n",
    "opac_dict = make_opacs(a_opac, lam_opac, porosity=porosity, n_theta=n_theta)\n",
    "fname_opac = opac_dict['filename']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part chops the very-forward scattering part of the phase function. This part is basically the same as no scattering, but are treated by the code as a scattering event. By cutting this part out of the phase function, we avoid those non-scattering scattering events. This needs to recalculate $\\kappa_{sca}$ and $g$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_opac_chopped = fname_opac.replace('.', '_chopped.')\n",
    "\n",
    "k_sca_nochop = opac_dict['k_sca']\n",
    "g_nochop = opac_dict['g']\n",
    "\n",
    "zscat, zscat_nochop, k_sca, g = chop_forward_scattering(opac_dict)\n",
    "\n",
    "opac_dict['k_sca'] = k_sca\n",
    "opac_dict['zscat'] = zscat\n",
    "opac_dict['g'] = g\n",
    "\n",
    "rho_s = opac_dict['rho_s']\n",
    "m = 4 * np.pi / 3 * rho_s * a_opac**3\n",
    "\n",
    "do.write_disklab_opacity(fname_opac_chopped, opac_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put all options in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {}\n",
    "\n",
    "options['disk'] = disk\n",
    "options['PA'] = PA\n",
    "options['inc'] = inc\n",
    "options['distance'] = dpc\n",
    "options['clip'] = clip\n",
    "options['lam_mm'] = lam_mm\n",
    "options['RMS_jyb'] = RMS_jyb\n",
    "options['mstar'] = mstar\n",
    "options['lstar'] = lstar\n",
    "options['tstar'] = tstar\n",
    "options['rstar'] = rstar\n",
    "\n",
    "# set the mm observables\n",
    "\n",
    "options['x_mm_obs'] = x_mm_obs\n",
    "options['y_mm_obs'] = y_mm_obs\n",
    "options['dy_mm_obs'] = dy_mm_obs\n",
    "options['fname_mm_obs'] = fname_mm_obs\n",
    "\n",
    "\n",
    "# set options used in the scattered light image\n",
    "\n",
    "options['z0'] = z0\n",
    "options['psi'] = psi\n",
    "options['lam_sca'] = lam_sca\n",
    "options['fname_sca_obs'] = fname_sca_obs\n",
    "options['beam_sca'] = beam_sca\n",
    "options['RMS_sca'] = RMS_sca\n",
    "\n",
    "# get the scattered light data\n",
    "\n",
    "options['profiles_sca_obs'] = profiles_sca_obs\n",
    "\n",
    "# name of the opacities file\n",
    "\n",
    "options['fname_opac'] = fname_opac_chopped\n",
    "\n",
    "# get the disklab model parameters\n",
    "\n",
    "options['nr'] = nr\n",
    "options['rin'] = rin\n",
    "options['r_c'] = r_c\n",
    "options['rout'] = rout\n",
    "options['alpha'] = alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emcee part\n",
    "\n",
    "here we define some inputs and initial parameter sets for the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining number of walkers\n",
    "nwalkers = 25\n",
    "ndim     = 7\n",
    "\n",
    "# setting the priors for some parameters instead of letting them be uniform randoms between (0.1)\n",
    "\n",
    "sigma_coeff_0   = 10**((np.random.rand(nwalkers)-0.5)*4)\n",
    "others_0        = np.random.rand(ndim-3,nwalkers)\n",
    "d2g_coeff_0     = (np.random.rand(nwalkers)+0.5) / 100\n",
    "d2g_exp_0       = (np.random.rand(nwalkers)-0.5) \n",
    "\n",
    "# the input matrix of priors\n",
    "p0 = np.vstack((sigma_coeff_0,others_0, d2g_coeff_0, d2g_exp_0)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here comes the rest of `MCMC_parallelized.py`, not cleaned up yet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procs = 1\n",
    "\n",
    "if procs > 1:\n",
    "    # Parallelizing the simluation and running it for 250 iterations\n",
    "    with Pool(processes=procs) as pool:\n",
    "        sampler1 = emcee.EnsembleSampler(nwalkers, ndim, logP.logP, args=[options], pool=pool)\n",
    "        sampler1.run_mcmc(p0, 250)\n",
    "else:\n",
    "    sampler1 = emcee.EnsembleSampler(nwalkers, ndim, logP.logP, args=[options])\n",
    "    sampler1.run_mcmc(p0, 250)\n",
    "\n",
    "print(sampler1.iteration)    \n",
    "\n",
    "print('step2')\n",
    "sampler2 = deepcopy(sampler1)\n",
    "sampler2.log_prob_fn = None\n",
    "with open('sampler.pickle', 'wb') as fid:\n",
    "    pickle.dump(sampler2, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to python testing.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h1 style=\"color:red;\">Testing area</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testparameters =[\n",
    "    7.0,\n",
    "    0.730,\n",
    "    0.558,\n",
    "    0.017,\n",
    "    0.625,\n",
    "    0.008,\n",
    "    0.050,\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logP\n",
    "from importlib import reload\n",
    "reload(logP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logp_value, debug_info = logP.logP(testparameters, options, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_sca_sim = debug_info['iq_sca_sim']\n",
    "iq_sca_obs = debug_info['iq_sca_obs']\n",
    "iq_mm_sim = debug_info['iq_mm_sim']\n",
    "iq_mm_obs = debug_info['iq_mm_obs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scattered light images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(10, 5), sharex=True, sharey=True)\n",
    "vmin = 5e-8\n",
    "vmax = 20 * vmin\n",
    "ax[0].imshow(iq_sca_sim.data, extent=iq_sca_sim.extent, vmin=vmin, vmax=vmax, origin='lower')\n",
    "ax[1].imshow(iq_sca_obs.data, extent=iq_sca_obs.extent, vmin=vmin, vmax=vmax, origin='lower')\n",
    "ax[0].set_xlim([2, -2])\n",
    "ax[0].set_ylim([-2, 2])\n",
    "\n",
    "ax[0].axis('off')\n",
    "ax[1].axis('off')\n",
    "f.subplots_adjust(wspace=0)\n",
    "f.savefig('sca.pdf', transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Radio Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_cgs_sim = iq_mm_sim.data * iq_mm_sim.pix_per_beam / iq_mm_sim.beamarea_str * 1e-23\n",
    "im_cgs_obs = iq_mm_obs.data / iq_mm_sim.beamarea_str * 1e-23\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(10, 5), sharex=True, sharey=True)\n",
    "vmin = RMS_jyb * 1e-23 / iq_mm_obs.beamarea_str # the RMS from dsharp (Jy/beam) to CGS conversion\n",
    "vmax = 20 * vmin\n",
    "ax[0].imshow(im_cgs_sim, extent=iq_mm_sim.extent, vmin=vmin, vmax=vmax, origin='lower')\n",
    "ax[1].imshow(im_cgs_obs, extent=iq_mm_obs.extent, vmin=vmin, vmax=vmax, origin='lower')\n",
    "ax[0].set_xlim([2, -2])\n",
    "ax[0].set_ylim([-2, 2]);\n",
    "\n",
    "ax[0].axis('off')\n",
    "ax[1].axis('off')\n",
    "f.subplots_adjust(wspace=0)\n",
    "f.savefig('mm.pdf', transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mm_sim = debug_info['x_mm_sim']\n",
    "y_mm_sim = debug_info['y_mm_sim']\n",
    "dy_mm_sim = debug_info['dy_mm_sim']\n",
    "\n",
    "x_sca_sim = debug_info['x_sca_sim']\n",
    "y_sca_sim = debug_info['y_sca_sim']\n",
    "dy_sca_sim = debug_info['dy_sca_sim']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we estimate the noise of the azimuthally averaged profile by dividing the RMS noise of the image by the approximate number of beams along the annulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin_avg = vmax / (2 * np.pi * x_mm_obs * np.sqrt(iq_mm_obs.beam[0] * iq_mm_obs.beam[1]) / iq_mm_obs.beamarea_arcsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the azimuthal profile and error estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(dpi=150)\n",
    "ax.semilogy(x_mm_obs, y_mm_obs, label='ALMA data')\n",
    "ax.fill_between(x_mm_obs, y_mm_obs - dy_mm_obs, y_mm_obs + dy_mm_obs, alpha=0.5)\n",
    "\n",
    "ax.semilogy(x_mm_sim, y_mm_sim, label='model')\n",
    "ax.fill_between(x_mm_sim, y_mm_sim - dy_mm_sim, y_mm_sim + dy_mm_sim, alpha=0.5)\n",
    "\n",
    "#ax.fill_between(x_mm_obs, y_mm_obs - (vmax * err_est), y_mm_obs + (vmax * err_est), alpha=0.5)\n",
    "\n",
    "ax.axhline(vmin, c='0.5', ls='--', label='image RMS noise')\n",
    "ax.semilogy(x_mm_obs, vmin_avg, c='k', ls='--', label='expected RMS noise of profile')\n",
    "\n",
    "ax.semilogy(x_mm_obs, np.maximum(y_mm_obs, vmin_avg), c='k', ls='-')\n",
    "\n",
    "#ax.set_xlim(1.5, 2.5);\n",
    "ax.set_ylim(5e-17, 1e-12)\n",
    "ax.set_xlabel('r [arcsec]')\n",
    "ax.set_ylabel('Intensity [erg/(s cm$^2$ Hz sr)]')\n",
    "ax.legend(fontsize='small')\n",
    "f.savefig('profile_mm.pdf', transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "\n",
    "- [ ] should we convolve with a beam?\n",
    "- [ ] calculate the logP from the profiles\n",
    "- [ ] find proper RMS for scattered light\n",
    "- [ ] make the image pixels the same as the observed ones\n",
    "- [ ] profile the `logP` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the profiles for logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_min = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disk_surface = dict(inc=inc, PA=PA, z0=z0, psi=psi)\n",
    "profile_options = dict(clip=clip, beam=iq_sca_obs.beam, r_min=r_min, **disk_surface)\n",
    "\n",
    "\n",
    "profiles_sca_sim = helper_functions.get_normalized_profiles(fname_sca_sim, **profile_options)\n",
    "profiles_sca_obs = helper_functions.get_normalized_profiles(fname_sca_obs, **profile_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMS = options['RMS']\n",
    "chi = 0\n",
    "for key in profiles_sca_obs.keys():\n",
    "    mask = profiles_sca_obs[key]['x'] > r_min\n",
    "    y_sim = np.interp(profiles_sca_obs[key]['x'][mask], profiles_sca_sim[key]['x'], profiles_sca_sim[key]['y'])\n",
    "    chi += ((profiles_sca_obs[key]['y'][mask] - y_sim)**2 / (2*RMS**2)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi / 1024**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in profiles_sca_sim.keys():\n",
    "\n",
    "    f, ax = plt.subplots()\n",
    "    \n",
    "    mask = profiles_sca_obs[key]['x'] > r_min\n",
    "\n",
    "    y_sim = np.interp(profiles_sca_obs[key]['x'][mask], profiles_sca_sim[key]['x'], profiles_sca_sim[key]['y'])\n",
    "\n",
    "    ax.semilogy(profiles_sca_obs[key]['x'], profiles_sca_obs[key]['y'], label='observation')\n",
    "    ax.fill_between(profiles_sca_obs[key]['x'], profiles_sca_obs[key]['y'] - profiles_sca_obs[key]['dy'], profiles_sca_obs[key]['y'] + profiles_sca_obs[key]['dy'])\n",
    "    ax.semilogy(profiles_sca_obs[key]['x'][mask], y_sim,'k--', label='simulation')\n",
    "    ax.set_title(key)\n",
    "    ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
